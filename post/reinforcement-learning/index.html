<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Cutive+Mono&family=Lora:wght@400;700&family=Roboto:wght@400;700&display=swap&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Cutive+Mono&family=Lora:wght@400;700&family=Roboto:wght@400;700&display=swap&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.47b429bcc548a9f3076e015326b37ecb.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=author content="Dr. Ehecatl Antonio del Rio Chanona"><meta name=description content><link rel=alternate hreflang=en-us href=https://optimalpse.github.io/post/reinforcement-learning/><link rel=canonical href=https://optimalpse.github.io/post/reinforcement-learning/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu5a76b0abcb7258b41069941c74c2d861_196285_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu5a76b0abcb7258b41069941c74c2d861_196285_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@wowchemy"><meta property="twitter:creator" content="@wowchemy"><meta property="twitter:image" content="https://optimalpse.github.io/post/reinforcement-learning/featured.jpg"><meta property="og:site_name" content="OptiML PSE"><meta property="og:url" content="https://optimalpse.github.io/post/reinforcement-learning/"><meta property="og:title" content="Reinforcement Learning for PSE | OptiML PSE"><meta property="og:description" content><meta property="og:image" content="https://optimalpse.github.io/post/reinforcement-learning/featured.jpg"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2024-05-07T00:00:00+00:00"><meta property="article:modified_time" content="2024-05-07T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://optimalpse.github.io/post/reinforcement-learning/"},"headline":"Reinforcement Learning for PSE","image":["https://optimalpse.github.io/post/reinforcement-learning/featured.jpg"],"datePublished":"2024-05-07T00:00:00Z","dateModified":"2024-05-07T00:00:00Z","author":{"@type":"Person","name":"Max Bloor"},"publisher":{"@type":"Organization","name":"OptiML PSE","logo":{"@type":"ImageObject","url":"https://optimalpse.github.io/media/logo_hu5a76b0abcb7258b41069941c74c2d861_196285_192x192_fit_lanczos_3.png"}},"description":""}</script><title>Reinforcement Learning for PSE | OptiML PSE</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=33a178cf80848e88e0171d10f194f54e><script src=/js/wowchemy-init.min.fe8634e7d00f14d07fb33caf14cc8e55.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex justify-content-center align-items-center w-100"><a class="navbar-brand d-flex align-items-center" href=/><img src=/media/logo_hu5a76b0abcb7258b41069941c74c2d861_196285_0x70_resize_lanczos_3.png alt="OptiML PSE"><span class=ml-3>OptiML PSE</span></a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-flex justify-content-center align-items-center d-lg-none w-100"><a class="navbar-brand d-flex align-items-center" href=/><img src=/media/logo_hu5a76b0abcb7258b41069941c74c2d861_196285_0x70_resize_lanczos_3.png alt="OptiML PSE"><span class=ml-3>OptiML PSE</span></a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Research</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/research/bayesian-optimization><span>Bayesian Optimization</span></a>
<a class=dropdown-item href=/research/data-driven-optimization><span>Data-Driven Optimization</span></a>
<a class=dropdown-item href=/research/supply-chain-optimization><span>Supply Chain Optimization</span></a>
<a class=dropdown-item href=/research/reinforcement-learning><span>Reinforcement Learning</span></a>
<a class=dropdown-item href=/research/statistical-learning><span>Statistical Learning</span></a>
<a class=dropdown-item href=/research/large-language-models><span>Large Language Models</span></a>
<a class=dropdown-item href=/research/hybrid-modelling><span>Hybrid Modelling</span></a>
<a class=dropdown-item href=/research/process-control><span>Process Control</span></a>
<a class=dropdown-item href=/research/deep-learning-in-ce><span>Deep Learning in Chemical Engineering</span></a></div></li><li class=nav-item><a class=nav-link href=/news><span>News</span></a></li><li class=nav-item><a class=nav-link href=/people><span>People</span></a></li><li class=nav-item><a class=nav-link href=/publication><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/learning-resources><span>Learning Resources</span></a></li><li class=nav-item><a class=nav-link href=/contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item d-none d-lg-inline-flex"><a class=nav-link href=https://github.com/OptiMaL-PSE-Lab target=_blank rel=noopener aria-label=github><i class="fab fa-github fa-xl" aria-hidden=true></i></a></li><li class="nav-item d-none d-lg-inline-flex"><a class=nav-link href=https://www.youtube.com/@optimlpse5033 target=_blank rel=noopener aria-label=youtube><i class="fab fa-youtube fa-xl" aria-hidden=true></i></a></li><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li></ul></div></nav></header></div><div class=page-body><article class=article><div class="article-container pt-3"><h1>Reinforcement Learning for PSE</h1><div class=article-metadata><div><span><a href=/author/max-bloor/>Max Bloor</a></span></div><span class=article-date>May 7, 2024
</span><span class=middot-divider></span>
<span class=article-reading-time>1 min read</span></div></div><div class=article-container><div class=article-style><table><thead><tr><th><figure><div class="d-flex justify-content-center"><div class=w-100><img alt srcset="/post/reinforcement-learning/featured_hu259738f748945f634c03d5b7c7684f95_59336_386b905ec9ce5ec08740b7d8221ade31.webp 400w,
/post/reinforcement-learning/featured_hu259738f748945f634c03d5b7c7684f95_59336_7ea9717ff29e37d494207021241c1e89.webp 760w,
/post/reinforcement-learning/featured_hu259738f748945f634c03d5b7c7684f95_59336_1200x1200_fit_q100_h2_lanczos.webp 1200w" src=/post/reinforcement-learning/featured_hu259738f748945f634c03d5b7c7684f95_59336_386b905ec9ce5ec08740b7d8221ade31.webp width=760 height=477 loading=lazy data-zoomable></div></div></figure></th><th><figure><div class="d-flex justify-content-center"><div class=w-100><img alt srcset="/post/reinforcement-learning/pc_hud3c0e97c9a69add1fe991c938a75f802_147783_0aacc75e6b3157927cf8140a963d4b0b.webp 400w,
/post/reinforcement-learning/pc_hud3c0e97c9a69add1fe991c938a75f802_147783_22e9fcfd6293c0cc4e550ac55ddf447d.webp 760w,
/post/reinforcement-learning/pc_hud3c0e97c9a69add1fe991c938a75f802_147783_1200x1200_fit_q100_h2_lanczos_3.webp 1200w" src=/post/reinforcement-learning/pc_hud3c0e97c9a69add1fe991c938a75f802_147783_0aacc75e6b3157927cf8140a963d4b0b.webp width=760 height=449 loading=lazy data-zoomable></div></div></figure></th></tr></thead></table><div style=text-align:justify>The chemical industry requires efficient control systems to operate at the border of process constraints while optimizing for profit, safety, and sustainability. Reinforcement Learning (RL) is a control philosophy that aims to address the complex control problems present in chemical systems. RL utilises plant data to improve its control performance and has several advantages over other control strategies such as its offline inference time and flexibility to adapt to changing plant conditions. However, RL is an active area of research to develop and implement algorithms suitable for industrial use global optimum due to its inherent robustness.</div></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Foptimalpse.github.io%2Fpost%2Freinforcement-learning%2F&amp;text=Reinforcement+Learning+for+PSE" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Foptimalpse.github.io%2Fpost%2Freinforcement-learning%2F&amp;t=Reinforcement+Learning+for+PSE" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Reinforcement%20Learning%20for%20PSE&amp;body=https%3A%2F%2Foptimalpse.github.io%2Fpost%2Freinforcement-learning%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Foptimalpse.github.io%2Fpost%2Freinforcement-learning%2F&amp;title=Reinforcement+Learning+for+PSE" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=Reinforcement+Learning+for+PSE%20https%3A%2F%2Foptimalpse.github.io%2Fpost%2Freinforcement-learning%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Foptimalpse.github.io%2Fpost%2Freinforcement-learning%2F&amp;title=Reinforcement+Learning+for+PSE" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=/author/max-bloor/><img class="avatar mr-3 avatar-circle" src=/author/max-bloor/avatar_hu08287478c51bf72a1b2593382b155b0d_90961_270x270_fill_q100_lanczos_center.jpg alt="Max Bloor"></a><div class=media-body><h5 class=card-title><a href=/author/max-bloor/>Max Bloor</a></h5><h6 class=card-subtitle>First Year PhD Candidate</h6><p class=card-text>Max is a PhD student with a research interest in applying and developing deep reinforcement learning algorithms for chemical process control. Before starting his PhD, he completed his undergraduate degree at the University of Edinburgh and his Masters degree at Imperial College London. Also, he has worked in industry as a process engineering consultant.</p><ul class=network-icon aria-hidden=true><li><a href=https://www.linkedin.com/in/maximilian-bloor/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=https://twitter.com/MaximilianBloor target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a href=https://github.com/MaximilianB2 target=_blank rel=noopener><i class="fab fa-github"></i></a></li></ul></div></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2024 OptiML PSE. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.b4708d4364577c16ab7001b265a063a4.js></script><script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script><script src=/en/js/wowchemy.min.4922cd6d3d810ab587afa7cdb3851db6.js></script><script src=/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.af9327db0521d4a01354bfc8b77a4324.js type=module></script></body></html>